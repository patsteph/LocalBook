# FastAPI and server
fastapi>=0.115.0
uvicorn[standard]>=0.32.0
python-multipart>=0.0.20
pydantic>=2.10.0
pydantic-settings>=2.6.0

# Vector database and embeddings
# Note: Install torch FIRST if you have issues (pip install torch)
lancedb>=0.18.0
sentence-transformers>=3.3.0
torch>=2.0.0  # 2.0+ works, earlier versions may work too

# LLM integrations
anthropic>=0.40.0
openai>=1.56.0
mistralai>=1.10.0  # Mistral API client
pydantic-ai>=0.0.30  # Structured LLM outputs with validation and retry

# LangChain/LangGraph for agent workflows
langchain-core>=0.3.0  # Allow 0.x or 1.x - we only use basic message/tool imports
langgraph>=0.2.0  # Allow 0.x or 1.x - basic graph functionality

# Security/Encryption
cryptography>=42.0.0  # For credential locker encryption

# Document processing
PyMuPDF>=1.25.0,<1.26.0  # Pin to 1.25.x - 1.26.x has raw_unicode_escape encoding bug
pymupdf4llm>=0.0.10  # RAG-optimized PDF extraction (Markdown output)
python-docx>=1.1.0
python-pptx>=1.0.0
openpyxl>=3.1.0
xlrd>=2.0.0
pandas>=2.2.0
ebooklib>=0.18  # EPUB support
pytesseract>=0.3.10  # OCR for images
Pillow>=10.0.0  # Image processing
nbformat>=5.9.0  # Jupyter notebook support
odfpy>=1.4.1  # OpenDocument (ODT) support
striprtf>=0.0.26  # RTF text extraction
olefile>=0.46  # Legacy DOC/PPT (OLE compound documents)

# Web scraping
trafilatura>=1.12.0
requests>=2.32.0
beautifulsoup4>=4.12.0

# YouTube
youtube-transcript-api>=0.6.0

# Audio/Video transcription (requires ffmpeg: brew install ffmpeg)
# v1.1.0: lightning-whisper-mlx is 10x faster on Apple Silicon
# Falls back to openai-whisper if MLX unavailable
lightning-whisper-mlx; sys_platform == "darwin"  # MLX only works on macOS
openai-whisper  # Fallback for non-Mac or if MLX fails

# System monitoring
psutil>=5.9.0  # For health portal system info

# Hybrid search (BM25 + Vector)
rank-bm25>=0.2.2  # BM25 keyword search for hybrid retrieval

# Reranking (FlashRank - ultra-fast, runs on CPU)
# NOTE: flashrank requires onnxruntime which may not be available on all platforms
# If installation fails, comment out and the app will use cross-encoder fallback
flashrank; platform_machine != "aarch64"  # Skip on ARM Linux where onnxruntime unavailable

# Topic modeling (BERTopic - state-of-the-art topic discovery)
bertopic>=0.16.0  # Includes HDBSCAN, UMAP, c-TF-IDF for automatic topic naming

# Utilities
python-dotenv>=1.0.0
httpx>=0.28.0
keyring>=25.5.0
dateparser>=1.2.0
tiktoken>=0.7.0  # Token counting for memory management
# hdbscan>=0.8.33  # Optional fallback - sklearn.cluster.HDBSCAN is preferred (sklearn 1.3+)
numpy>=1.21.0  # Looser requirement for compatibility
pyarrow>=14.0.0

# Build tools (for creating distributable binary)
pyinstaller>=6.0.0
